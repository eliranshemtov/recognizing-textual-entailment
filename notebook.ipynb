{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text entailment using BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tunning helper resources: \n",
    "- https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
    "- https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import wget\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = 1.0\n",
    "MODEL_PATH = f'./saved_model/{MODEL_VERSION}'\n",
    "MODEL_HISTORY_PATH = f'{MODEL_PATH}/history.csv'\n",
    "\n",
    "DATASET_URL = 'https://nlp.stanford.edu/projects/snli/snli_1.0.zip'\n",
    "DATASET_DIR_PATH = './data'\n",
    "DATASET_NAME = 'snli_1.0'\n",
    "DATASET_DOWNLOAD_PATH = f'{DATASET_DIR_PATH}/{DATASET_NAME}.zip'\n",
    "DATA_DEV = f'{DATASET_DIR_PATH}/{DATASET_NAME}/snli_1.0_dev.txt'\n",
    "DATA_TEST = f'{DATASET_DIR_PATH}/{DATASET_NAME}/snli_1.0_test.txt'\n",
    "DATA_TRAIN = f'{DATASET_DIR_PATH}/{DATASET_NAME}/snli_1.0_train.txt'\n",
    "DATA_TOKENIZE_DEV = f'{DATASET_DIR_PATH}/{DATASET_NAME}/snli_1.0_tokenize_dev_.pkl'\n",
    "DATA_TOKENIZE_TEST = f'{DATASET_DIR_PATH}/{DATASET_NAME}/snli_1.0_tokenize_test.pkl'\n",
    "DATA_TOKENIZE_TRAIN = f'{DATASET_DIR_PATH}/{DATASET_NAME}/snli_1.0_tokenize_train.pkl'\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "LABELS = {'neutral': 0, 'contradiction': 1, 'entailment': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(DATASET_DIR_PATH):\n",
    "    os.mkdir(DATASET_DIR_PATH)\n",
    "    wget.download(DATASET_URL, out=DATASET_DOWNLOAD_PATH)\n",
    "    \n",
    "    with zipfile.ZipFile(DATASET_DOWNLOAD_PATH, 'r') as z:\n",
    "        z.extractall(DATASET_DIR_PATH)\n",
    "        os.remove(DATASET_DOWNLOAD_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset already tokenized\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(DATA_TOKENIZE_TRAIN) and not os.path.isfile(DATA_TOKENIZE_DEV) and not os.path.isfile(DATA_TOKENIZE_TEST):\n",
    "        \n",
    "    # Load the base dataset\n",
    "    def load_and_preprocessing(csv_file: str):\n",
    "        data = pd.read_csv(csv_file, sep='\\t')\n",
    "        data = data[['gold_label', 'sentence1', 'sentence2']]\n",
    "        data = data[data['gold_label'] != '-']\n",
    "        data.dropna(inplace=True)\n",
    "\n",
    "        data['sentence'] = '[CLS]' + data['sentence1'] + '[SEP]' + data['sentence2'] + '[SEP]'\n",
    "        data['tokens'] = data['sentence'].apply(tokenizer.tokenize)\n",
    "        data['gold_label_int'] = data['gold_label'].apply(lambda l: LABELS[l])\n",
    "\n",
    "        return data\n",
    "\n",
    "    train = load_and_preprocessing(csv_file=DATA_TRAIN)\n",
    "    dev = load_and_preprocessing(csv_file=DATA_DEV)\n",
    "    test = load_and_preprocessing(csv_file=DATA_TEST)\n",
    "\n",
    "    # Find the max length \n",
    "    # +3 is for [SEP] [SEP] [CLS]\n",
    "    max_len = len(max([max(df['tokens'], key=len) for df in [train, dev, test]], key=len)) + 3\n",
    "    print(f'max len: {max_len}')\n",
    "\n",
    "    def encode_process(data: pd.DataFrame):\n",
    "        def encode(sentence: str, max_len: int):\n",
    "            return tokenizer.encode_plus(\n",
    "                sentence,\n",
    "                return_tensors='pt',\n",
    "                add_special_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "                padding='max_length',\n",
    "                max_length=max_len,\n",
    "            )\n",
    "\n",
    "        data['token_encoded'] = data['sentence'].apply(lambda sen: encode(sen, max_len))\n",
    "        data[['input_ids', 'token_type_ids', 'attention_mask']] = data['token_encoded'].apply(pd.Series)\n",
    "        data.drop(['token_encoded', 'tokens'], axis=1, inplace=True)\n",
    "\n",
    "    encode_process(train)\n",
    "    train.to_pickle(DATA_TOKENIZE_TRAIN)\n",
    "\n",
    "    encode_process(dev)\n",
    "    dev.to_pickle(DATA_TOKENIZE_DEV)\n",
    "\n",
    "    encode_process(test)\n",
    "    test.to_pickle(DATA_TOKENIZE_TEST)\n",
    "\n",
    "else:   \n",
    "    print('The dataset already tokenized')\n",
    "    \n",
    "train = pd.read_pickle(DATA_TOKENIZE_TRAIN)\n",
    "dev = pd.read_pickle(DATA_TOKENIZE_DEV)\n",
    "test = pd.read_pickle(DATA_TOKENIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(dataset: pd.DataFrame):\n",
    "    input_ids = torch.cat(tuple(dataset['input_ids'].values))\n",
    "    attention_mask = torch.cat(tuple(dataset['attention_mask'].values))\n",
    "    labels = torch.tensor(dataset['gold_label_int'].values)\n",
    "\n",
    "    return TensorDataset(input_ids, attention_mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = create_tensor_dataset(train)\n",
    "dev_tensor = create_tensor_dataset(dev)\n",
    "test_tensor = create_tensor_dataset(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=BATCH_SIZE, sampler=RandomSampler(train_tensor))\n",
    "dev_loader = DataLoader(dev_tensor, batch_size=BATCH_SIZE, sampler=SequentialSampler(dev_tensor))\n",
    "test_loader = DataLoader(test_tensor, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=3, output_attentions=False, output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69fcc0ce06e40edafd6033c55473b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b8597ee27b4897bf5d91cc50fceb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e399cce1802c46d9b58d5e6bb8aef12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fbe9cd630d4b5aa33cbc179604e9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa0d47f6741405799ff142b066271e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f40ea4da0d240a3abeeec36f4268452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.isdir(MODEL_PATH):\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        print(f'Epoch {epoch + 1}/{max_epoch}')\n",
    "\n",
    "        # Training\n",
    "        train_bar = tqdm(total=len(train_loader), position=1, desc=\"Training\")\n",
    "        \n",
    "        total_train_loss = 0\n",
    "\n",
    "        model.train()  \n",
    "\n",
    "        for batch in train_loader:\n",
    "            # squeeze fix the tensor dimenssion\n",
    "            batch_ids = batch[0].squeeze(1).to(device)\n",
    "            batch_masks = batch[1].squeeze(1).to(device)\n",
    "            batch_labels = batch[2].to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(batch_ids, token_type_ids = None, attention_mask = batch_masks, labels = batch_labels)\n",
    "            loss = output.loss\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            train_bar.update(1)\n",
    "            train_bar.set_postfix({'loss': total_train_loss / len(train_loader)})\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Evaluation\n",
    "        eval_bar = tqdm(total=len(dev_loader), position=0, desc=\"Validation\")\n",
    "        \n",
    "        total_eval_loss = 0\n",
    "        total_eval_accuracy = 0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch in dev_loader:\n",
    "            batch_ids = batch[0].squeeze(1).to(device)\n",
    "            batch_masks = batch[1].squeeze(1).to(device)\n",
    "            batch_labels = batch[2].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(batch_ids, token_type_ids = None, attention_mask = batch_masks, labels = batch_labels)\n",
    "        \n",
    "            total_eval_loss += output.loss.item()\n",
    "            \n",
    "            # Accumulate the accuracy\n",
    "            logits = output.logits.numpy()\n",
    "            logits_labels = np.argmax(logits, axis=1)\n",
    "            accuracy = np.sum(logits_labels == batch_labels.numpy()) / len(batch_labels)\n",
    "            total_eval_accuracy += accuracy\n",
    "\n",
    "            eval_bar.update(1)\n",
    "            eval_bar.set_postfix({'loss': total_train_loss / len(train_loader), 'acc': total_eval_accuracy / len(dev_loader)})\n",
    "\n",
    "        avg_eval_loss = total_eval_loss / len(dev_loader)\n",
    "        avg_eval_accuracy = total_eval_accuracy / len(dev_loader)\n",
    "\n",
    "        history.append({\n",
    "            'epoch': epoch,\n",
    "            'training_loss': avg_train_loss,\n",
    "            'validation_loss': avg_eval_loss,\n",
    "            'validation_accuracy': avg_eval_accuracy\n",
    "        })\n",
    "\n",
    "        # Save every epoch\n",
    "        model.save_pretrained(MODEL_PATH)\n",
    "        pd.DataFrame(history).set_index('epoch').to_csv(MODEL_HISTORY_PATH)\n",
    "\n",
    "else:\n",
    "    print(f'Model version {MODEL_VERSION} already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.171065</td>\n",
       "      <td>1.172204</td>\n",
       "      <td>0.343673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.143826</td>\n",
       "      <td>1.139167</td>\n",
       "      <td>0.333469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.106954</td>\n",
       "      <td>1.133112</td>\n",
       "      <td>0.333061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  training_loss  validation_loss  validation_accuracy\n",
       "0      0       1.171065         1.172204             0.343673\n",
       "1      1       1.143826         1.139167             0.333469\n",
       "2      2       1.106954         1.133112             0.333061"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = pd.read_csv(MODEL_HISTORY_PATH)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_model = BertForSequenceClassification.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c37c76da4e44ae3a0268038a8eecb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy\n",
    "l_model.eval()\n",
    "\n",
    "prediction, true_labeles = [], []\n",
    "test_bar = tqdm(total=len(test_loader), desc=\"Testing\")\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch_ids = batch[0].squeeze(1).to(device)\n",
    "    batch_masks = batch[1].squeeze(1).to(device)\n",
    "    batch_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = l_model(batch_ids, token_type_ids = None, attention_mask = batch_masks)\n",
    "\n",
    "    logits = output.logits\n",
    "    prediction.append(np.argmax(logits.numpy(), axis=1))\n",
    "    true_labeles.append(batch_labels.numpy())\n",
    "\n",
    "    test_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['training_loss'], label='Training')\n",
    "plt.plot(history['validation_loss'], label='Validation')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(range(max_epoch))\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.32      0.48        90\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.11      0.44      0.18         9\n",
      "\n",
      "    accuracy                           0.33        99\n",
      "   macro avg       0.35      0.26      0.22        99\n",
      "weighted avg       0.86      0.33      0.45        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_prediction = np.concatenate(prediction)\n",
    "all_true_labels = np.concatenate(true_labeles)\n",
    "\n",
    "print(classification_report(all_prediction, all_true_labels, labels=np.unique(all_true_labels), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7db71afcf4b806bd24d35d8a0617ebdde69a5c1f1646280c1ec86ff18ed7460"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
